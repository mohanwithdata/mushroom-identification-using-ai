{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b950fb-049c-4d2b-bbaf-86c028a5b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Input\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da587d8-8294-4d71-9deb-967a9cbfaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path\n",
    "data_dir = r'D:\\Project\\aug_data\\paper_data_aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d9d215-a31d-40cb-8f0d-9ded37e0343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter epochs number:  20\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "image_size = (img_height, img_width)\n",
    "epochs = int(input(\"Enter epochs number: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9d2734-bcc8-43c7-b2a8-a249748aada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 513 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'  # Force RGB mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209763fb-626c-444b-a690-e3993ad81893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91acf18-87ce-4c82-a2df-722dbd7e7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),  # Define input explicitly\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922d310a-3c99-47c3-9721-3d9ba243dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               22151424  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 22,245,700\n",
      "Trainable params: 22,245,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b888b107-3bfd-4cd0-b83d-57415457d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cbe30-45f4-4b70-9cbf-d8896dc648c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 27s 908ms/step - loss: 1.7873 - accuracy: 0.3450 - val_loss: 1.0009 - val_accuracy: 0.4752\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.6657 - accuracy: 0.7329 - val_loss: 0.7047 - val_accuracy: 0.7525\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.4411 - accuracy: 0.8265 - val_loss: 0.3137 - val_accuracy: 0.8713\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 16s 961ms/step - loss: 0.2974 - accuracy: 0.8596 - val_loss: 0.3781 - val_accuracy: 0.8218\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 17s 976ms/step - loss: 0.2436 - accuracy: 0.8928 - val_loss: 0.4281 - val_accuracy: 0.8515\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2040 - accuracy: 0.9123 - val_loss: 0.1715 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 16s 947ms/step - loss: 0.1567 - accuracy: 0.9376 - val_loss: 0.2392 - val_accuracy: 0.8614\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.1420 - accuracy: 0.9396 - val_loss: 0.0935 - val_accuracy: 0.9604\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 17s 970ms/step - loss: 0.0818 - accuracy: 0.9649 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 16s 953ms/step - loss: 0.0581 - accuracy: 0.9786 - val_loss: 0.0756 - val_accuracy: 0.9406\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 17s 973ms/step - loss: 0.0512 - accuracy: 0.9825 - val_loss: 0.0551 - val_accuracy: 0.9703\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.0981 - accuracy: 0.9708 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 17s 961ms/step - loss: 0.1262 - accuracy: 0.9649 - val_loss: 0.0328 - val_accuracy: 0.9901\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 17s 972ms/step - loss: 0.1245 - accuracy: 0.9630 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.2401 - accuracy: 0.9259 - val_loss: 0.1360 - val_accuracy: 0.9307\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2876 - accuracy: 0.8772 - val_loss: 0.3359 - val_accuracy: 0.8416\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.2124 - accuracy: 0.9259 - val_loss: 0.1972 - val_accuracy: 0.9109\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.0908 - accuracy: 0.9669 - val_loss: 0.0915 - val_accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a39f75-7a7d-4f93-95ce-126ff7fadb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy', fontsize=14)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68091f5c-d55e-4af7-a52f-5ed6ff62ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "eval_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_true = eval_generator.classes\n",
    "y_pred = model.predict(eval_generator)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Fix tf.argmax issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0681fa8-ccc3-4046-9e24-9ff5a8365283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_classes))\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred_classes)\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1931d7e-486b-45d1-890b-2d71af042a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"viridis\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4da00-72fa-46e7-98c1-cbeb993137da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = epochs\n",
    "next_version = str(int(model_version) + 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832571c-2c70-4f6d-b519-f45d9601616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "notebook_filename = f\"CNN_{model_version}_ADAM_aug.ipynb\"\n",
    "new_notebook_filename = f\"CNN_{next_version}_ADAM_aug.ipynb\"\n",
    "\n",
    "shutil.copy(notebook_filename, new_notebook_filename)\n",
    "print(f\"Notebook copied as {new_notebook_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45b82c-4eef-43e6-93cf-79a72b7ce4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
